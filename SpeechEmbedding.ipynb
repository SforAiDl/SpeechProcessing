{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>text</th>\n",
       "      <th>up_votes</th>\n",
       "      <th>down_votes</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>accent</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cv-valid-train/sample-000005.mp3</td>\n",
       "      <td>a shepherd may like to travel but he should ne...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>twenties</td>\n",
       "      <td>female</td>\n",
       "      <td>us</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cv-valid-train/sample-000008.mp3</td>\n",
       "      <td>put jackie right on the staff</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>seventies</td>\n",
       "      <td>male</td>\n",
       "      <td>us</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>cv-valid-train/sample-000013.mp3</td>\n",
       "      <td>but he had found a guide and didn't want to mi...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>thirties</td>\n",
       "      <td>female</td>\n",
       "      <td>us</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>cv-valid-train/sample-000014.mp3</td>\n",
       "      <td>as they began to decorate the hallway a silhou...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sixties</td>\n",
       "      <td>male</td>\n",
       "      <td>england</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>cv-valid-train/sample-000019.mp3</td>\n",
       "      <td>then they got ahold of some dough and went goofy</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>fifties</td>\n",
       "      <td>male</td>\n",
       "      <td>australia</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            filename  \\\n",
       "5   cv-valid-train/sample-000005.mp3   \n",
       "8   cv-valid-train/sample-000008.mp3   \n",
       "13  cv-valid-train/sample-000013.mp3   \n",
       "14  cv-valid-train/sample-000014.mp3   \n",
       "19  cv-valid-train/sample-000019.mp3   \n",
       "\n",
       "                                                 text  up_votes  down_votes  \\\n",
       "5   a shepherd may like to travel but he should ne...         1           0   \n",
       "8                       put jackie right on the staff         3           0   \n",
       "13  but he had found a guide and didn't want to mi...         1           0   \n",
       "14  as they began to decorate the hallway a silhou...         1           0   \n",
       "19   then they got ahold of some dough and went goofy         1           0   \n",
       "\n",
       "          age  gender     accent  duration  \n",
       "5    twenties  female         us       NaN  \n",
       "8   seventies    male         us       NaN  \n",
       "13   thirties  female         us       NaN  \n",
       "14    sixties    male    england       NaN  \n",
       "19    fifties    male  australia       NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"cv_corpus_v1/cv_corpus_v1/cv-valid-train.csv\")\n",
    "df=df.dropna(thresh=5)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 63)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar=df[\"filename\"].as_matrix()\n",
    "ar=ar[:5000]\n",
    "\n",
    "ms, _ =librosa.load(\"cv_corpus_v1/cv_corpus_v1/\"+ar[0])\n",
    "ms=ms[:25000]\n",
    "k = librosa.feature.melspectrogram(y=ms,hop_length=400,n_fft=1600,n_mels=80)\n",
    "k.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PreNet,self).__init__()\n",
    "        self.layer = nn.Sequential(\n",
    "                        nn.Linear(63,128),\n",
    "                        nn.ELU(),\n",
    "                        nn.Linear(128,128),\n",
    "                        nn.ELU(),\n",
    "                        nn.Linear(128,11),\n",
    "                        nn.ELU()\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.layer(x)\n",
    "        return x\n",
    "    \n",
    "pnet = PreNet()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet,self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "                        nn.Conv1d(80,80,12,padding=35),\n",
    "                        nn.GLU(),\n",
    "                        nn.Conv1d(80,80,12,padding=11),\n",
    "                        nn.GLU(),\n",
    "                        nn.Conv1d(80,80,12,padding=5),\n",
    "                        nn.GLU()\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.layer1(x)\n",
    "       \n",
    "        return x\n",
    "    \n",
    "cnet = ConvNet()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 80, 11])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = Variable(torch.from_numpy(k).type(torch.FloatTensor))\n",
    "z = z.view(1,1,80,63)\n",
    "o = pnet(z)\n",
    "o = o.view(1,80,11)\n",
    "\n",
    "o2 = cnet(o)\n",
    "\n",
    "\n",
    "newo = o+o2\n",
    "newo.data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreEncoderLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PreEncoderLayer,self).__init__()\n",
    "        self.layer = nn.Sequential(\n",
    "                        nn.Linear(11,128),\n",
    "                        nn.ELU()\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.layer(x)\n",
    "        return x\n",
    "    \n",
    "PEnLnet = PreEncoderLayer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 80, 128])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys = PEnLnet(newo)\n",
    "queries = values = keys\n",
    "keys.data.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self,\n",
    "                 query_dim,\n",
    "                 key_dim,\n",
    "                 num_units,\n",
    "                 dropout_p=0.5,\n",
    "                 h=2,\n",
    "                 is_masked=False):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "\n",
    "        if query_dim != key_dim:\n",
    "            raise ValueError(\"query_dim and key_dim must be the same\")\n",
    "        if num_units % h != 0:\n",
    "            raise ValueError(\"num_units must be dividable by h\")\n",
    "        if query_dim != num_units:\n",
    "            raise ValueError(\"to employ residual connection, the number of \"\n",
    "                             \"query_dim and num_units must be the same\")\n",
    "\n",
    "        self._num_units = num_units\n",
    "        self._h = h\n",
    "        self._key_dim = Variable(torch.FloatTensor([key_dim]))\n",
    "        self._dropout_p = dropout_p\n",
    "        self._is_masked = is_masked\n",
    "\n",
    "        self.query_layer = nn.Linear(query_dim, num_units, bias=False)\n",
    "        self.key_layer = nn.Linear(key_dim, num_units, bias=False)\n",
    "        self.value_layer = nn.Linear(key_dim, num_units, bias=False)\n",
    "        self.bn = nn.BatchNorm1d(num_units)\n",
    "\n",
    "    def forward(self, query, keys):\n",
    "        Q = self.query_layer(query)\n",
    "        K = self.key_layer(keys)\n",
    "        V = self.value_layer(keys)\n",
    "\n",
    "        # split each Q, K and V into h different values from dim 2\n",
    "        # and then merge them back together in dim 0\n",
    "        chunk_size = int(self._num_units / self._h)\n",
    "        Q = torch.cat(Q.split(split_size=chunk_size, dim=2), dim=0)\n",
    "        K = torch.cat(K.split(split_size=chunk_size, dim=2), dim=0)\n",
    "        V = torch.cat(V.split(split_size=chunk_size, dim=2), dim=0)\n",
    "\n",
    "        # calculate QK^T\n",
    "        attention = torch.matmul(Q, K.transpose(1, 2))\n",
    "        # normalize with sqrt(dk)\n",
    "        attention = attention / torch.sqrt(self._key_dim)\n",
    "        # use masking (usually for decoder) to prevent leftward\n",
    "        # information flow and retains auto-regressive property\n",
    "        # as said in the paper\n",
    "        if self._is_masked:\n",
    "            diag_vals = attention[0].sign().abs()\n",
    "            diag_mat = diag_vals.tril()\n",
    "            diag_mat = diag_mat.unsqueeze(0).expand(attention.size())\n",
    "            # we need to enforce converting mask to Variable, since\n",
    "            # in pytorch we can't do operation between Tensor and\n",
    "            # Variable\n",
    "            mask = Variable(\n",
    "                torch.ones(diag_mat.size()) * (-2**32 + 1), requires_grad=False)\n",
    "            # this is some trick that I use to combine the lower diagonal\n",
    "            # matrix and its masking. (diag_mat-1).abs() will reverse the value\n",
    "            # inside diag_mat, from 0 to 1 and 1 to zero. with this\n",
    "            # we don't need loop operation andn could perform our calculation\n",
    "            # faster\n",
    "            attention = (attention * diag_mat) + (mask * (diag_mat-1).abs())\n",
    "        # put it to softmax\n",
    "        attention = F.softmax(attention, dim=-1)\n",
    "        # apply dropout\n",
    "        attention = F.dropout(attention, self._dropout_p)\n",
    "        # multiplyt it with V\n",
    "        attention = torch.matmul(attention, V)\n",
    "        # convert attention back to its input original size\n",
    "        restore_chunk_size = int(attention.size(0) / self._h)\n",
    "        attention = torch.cat(\n",
    "            attention.split(split_size=restore_chunk_size, dim=0), dim=2)\n",
    "        # residual connection\n",
    "        attention += query\n",
    "        # apply batch normalization\n",
    "        attention = self.bn(attention.transpose(1, 2)).transpose(1, 2)\n",
    "\n",
    "        return attention\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention = MultiHeadAttention(128,128,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
